{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d281c42f-df52-419f-8da0-d17457b5ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression as SKLLR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from linear_regression import CloseFormSol, GradientDescent, AdaGrad, GradientDescentBiasSep, AdaGradBiasSep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95f318e-b95a-4cc0-bc57-edd00371498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = 'data/train.csv'\n",
    "test_csv_path = 'data/test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "test_df = pd.read_csv(test_csv_path, header=None)\n",
    "\n",
    "train_df = train_df.rename(columns={\"日期\": \"date\", \"測站\": \"station\", \"測項\": \"obs_item\"})\n",
    "\n",
    "train_df = train_df.replace('NR', 0)\n",
    "test_df = test_df.replace('NR', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fceece87-5a69-4067-9b55-6f6fbb90dd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in train df = False\n",
      "NaN in test df = False\n",
      "train val dtype = float64\n",
      "test val dtype = float64\n"
     ]
    }
   ],
   "source": [
    "train_df[train_df.columns[3:]] = train_df[train_df.columns[3:]].apply(pd.to_numeric, errors='coerce')\n",
    "test_df[test_df.columns[2:]] = test_df[test_df.columns[2:]].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(f\"NaN in train df = {train_df.isnull().values.any()}\")\n",
    "print(f\"NaN in test df = {test_df.isnull().values.any()}\")\n",
    "print(f\"train val dtype = {train_df[train_df.columns[3:]].values.dtype}\")\n",
    "print(f\"test val dtype = {test_df[test_df.columns[2:]].values.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4592acb8-b9b2-4ebb-b35a-96dc03290882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_x_train_y(train_df: pd.DataFrame):\n",
    "    fc = 18  # feature count\n",
    "    \n",
    "    # get year data\n",
    "    year_data = list()\n",
    "    for month in range(12):  # 0 - 11\n",
    "        total_hr = 24 * 20\n",
    "        temp = np.zeros((fc, total_hr))\n",
    "\n",
    "        day_per_month = 20\n",
    "        for day in range(day_per_month):\n",
    "            hr_idx = 24 * day\n",
    "            row_idx = 18 * 20 * month + 18 * day\n",
    "            temp[:, hr_idx : hr_idx + 24] = train_df.iloc[row_idx : row_idx + 18]\n",
    "\n",
    "        year_data.append(temp)\n",
    "\n",
    "    year_data = np.array(year_data)\n",
    "    \n",
    "    train_x, train_y = list(), list()\n",
    "    \n",
    "    for month in range(12):\n",
    "        month_data = year_data[month]\n",
    "        for hr_itv_idx in range(24 * 20 - 9):\n",
    "            x = month_data[:, hr_itv_idx : hr_itv_idx + 9].flatten()\n",
    "            y = month_data[9, hr_itv_idx + 9]  # pm2.5 is at row-9\n",
    "\n",
    "            train_x.append(x)\n",
    "            train_y.append(y)\n",
    "    \n",
    "    train_x, train_y = np.array(train_x), np.array(train_y)\n",
    "    print(f\"train_x, shape = {train_x.shape}\")\n",
    "    print(f\"train_y, shape = {train_y.shape}\")\n",
    "    \n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def get_test_x(test_df: pd.DataFrame):\n",
    "    test_x = list()\n",
    "    for i in range(0, len(test_df), 18):\n",
    "        sub_df = test_df.iloc[i:i+18, 2:]\n",
    "        test_x.append(sub_df.values.flatten())\n",
    "        \n",
    "    test_x = np.array(test_x)\n",
    "    print(f\"test_x, shape = {test_x.shape}\")\n",
    "    \n",
    "    return test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2635294-6156-42bc-ab71-4dfe5447e9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x, shape = (5652, 162)\n",
      "train_y, shape = (5652,)\n",
      "test_x, shape = (240, 162)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = get_train_x_train_y(train_df.iloc[:, 3:])\n",
    "test_x = get_test_x(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67afe8f4-5498-4d35-8c90-ec9c0c49961f",
   "metadata": {},
   "source": [
    "# Close Form Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e0e19ea-96b3-4d8f-acc5-01b2635b8ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs = CloseFormSol()\n",
    "cfs.fit(train_x, train_y)\n",
    "cfs_pred = cfs.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd46c0f0-e196-4293-98a8-e845b637889d",
   "metadata": {},
   "source": [
    "# Sklearn Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd2827d7-19cc-4793-9f22-df9a4fd2b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_lr = SKLLR()\n",
    "skl_lr.fit(train_x, train_y)\n",
    "skl_pred = skl_lr.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ead0a88-5c28-4fd4-a00b-1d3c09a41449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffence between Close Form Solution and Sklearn Linear Regression = 0.0\n"
     ]
    }
   ],
   "source": [
    "diff = mean_squared_error(cfs_pred, skl_pred)\n",
    "print(f\"Diffence between Close Form Solution and Sklearn Linear Regression = {round(diff, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f930a77c-58dd-4fe0-aebb-9f1e49e59cf4",
   "metadata": {},
   "source": [
    "# My Own Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c33b23d-fc0e-4aee-9ea4-2b4dd60eebe1",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fdd816-56f8-4cc6-af68-139fa721c6c0",
   "metadata": {},
   "source": [
    "### add bias into w solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ad7ef96-22d3-4d1c-b1d9-241638e52575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost  732.851   \n",
      "Iteration 1000: Cost   73.409   \n",
      "Iteration 2000: Cost   61.568   \n",
      "Iteration 3000: Cost   55.562   \n",
      "Iteration 4000: Cost   51.737   \n",
      "Iteration 5000: Cost   49.037   \n",
      "Iteration 6000: Cost   47.016   \n",
      "Iteration 7000: Cost   45.441   \n",
      "Iteration 8000: Cost   44.177   \n",
      "Iteration 9000: Cost   43.138   \n"
     ]
    }
   ],
   "source": [
    "gd = GradientDescent(iteration=10000, lr=1e-6)\n",
    "gd.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2686280-4c47-4e80-92cd-4bb50c4b372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffence between Close Form Solution and My Gradient Descent = 11.054\n"
     ]
    }
   ],
   "source": [
    "gd_pred = gd.predict(test_x)\n",
    "\n",
    "diff = mean_squared_error(cfs_pred, gd_pred)\n",
    "print(f\"Diffence between Close Form Solution and My Gradient Descent = {round(diff, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9571d087-563a-4aa7-93e3-06bada19040a",
   "metadata": {},
   "source": [
    "### seperate bias solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fba371d-6ee5-4b53-99d9-80d242fe1d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost  732.851   \n",
      "Iteration 1000: Cost   73.409   \n",
      "Iteration 2000: Cost   61.568   \n",
      "Iteration 3000: Cost   55.562   \n",
      "Iteration 4000: Cost   51.737   \n",
      "Iteration 5000: Cost   49.037   \n",
      "Iteration 6000: Cost   47.016   \n",
      "Iteration 7000: Cost   45.441   \n",
      "Iteration 8000: Cost   44.177   \n",
      "Iteration 9000: Cost   43.138   \n"
     ]
    }
   ],
   "source": [
    "gd_bs = GradientDescentBiasSep(iteration=10000, lr=1e-6)\n",
    "gd_bs.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5f0d87e-4079-4f82-985f-9d40594bd66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffence between Close Form Solution and My Gradient Descent BS = 11.054\n"
     ]
    }
   ],
   "source": [
    "gd_bs_pred = gd_bs.predict(test_x)\n",
    "\n",
    "diff = mean_squared_error(cfs_pred, gd_bs_pred)\n",
    "print(f\"Diffence between Close Form Solution and My Gradient Descent BS = {round(diff, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9fecb4-482b-485c-bb92-36345acf793e",
   "metadata": {},
   "source": [
    "### AdaGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bba807-bac5-48b0-91ea-9252d5658837",
   "metadata": {},
   "source": [
    "### add bias to w solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e5802aa-76ad-41c1-9fe8-7da0789e2b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost  732.851   \n",
      "Iteration 1000: Cost   49.866   \n",
      "Iteration 2000: Cost   42.866   \n",
      "Iteration 3000: Cost   39.827   \n",
      "Iteration 4000: Cost   38.112   \n",
      "Iteration 5000: Cost   37.002   \n",
      "Iteration 6000: Cost   36.222   \n",
      "Iteration 7000: Cost   35.642   \n",
      "Iteration 8000: Cost   35.194   \n",
      "Iteration 9000: Cost   34.837   \n"
     ]
    }
   ],
   "source": [
    "ada_grad = AdaGrad(iteration=10000, lr=1.5)\n",
    "ada_grad.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c641a3c-eb0f-413c-a216-02e8291e0d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffence between Close Form Solution and My Adagrad = 2.805\n"
     ]
    }
   ],
   "source": [
    "ada_pred = ada_grad.predict(test_x)\n",
    "\n",
    "diff = mean_squared_error(cfs_pred, ada_pred)\n",
    "print(f\"Diffence between Close Form Solution and My Adagrad = {round(diff, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668b5142-7d77-4244-9b3c-72f087f6f7c0",
   "metadata": {},
   "source": [
    "### seperate bias solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab5058b0-db50-4b83-953b-9088ee4ce95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost  732.851   \n",
      "Iteration 1000: Cost   49.866   \n",
      "Iteration 2000: Cost   42.866   \n",
      "Iteration 3000: Cost   39.827   \n",
      "Iteration 4000: Cost   38.112   \n",
      "Iteration 5000: Cost   37.002   \n",
      "Iteration 6000: Cost   36.222   \n",
      "Iteration 7000: Cost   35.642   \n",
      "Iteration 8000: Cost   35.194   \n",
      "Iteration 9000: Cost   34.837   \n"
     ]
    }
   ],
   "source": [
    "ada_grad_bs = AdaGradBiasSep(iteration=10000, lr=1.5)\n",
    "ada_grad_bs.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3bb8dcf-2303-45cd-b305-d7abaa380602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffence between Close Form Solution and My Adagrad BS = 2.805\n"
     ]
    }
   ],
   "source": [
    "ada_bs_pred = ada_grad_bs.predict(test_x)\n",
    "\n",
    "diff = mean_squared_error(cfs_pred, ada_bs_pred)\n",
    "print(f\"Diffence between Close Form Solution and My Adagrad BS = {round(diff, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbaecc8-8a6d-46fd-a9e8-f1bc7dd732c7",
   "metadata": {},
   "source": [
    "### AdaGrad with Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b95e91c-9db7-4aec-a04e-2ad0986a8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_x_norm = scaler.fit_transform(train_x)\n",
    "test_x_norm = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cbd570a-4392-401d-8ee0-3b6f297043fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost  732.851   \n",
      "Iteration 1000: Cost   33.992   \n",
      "Iteration 2000: Cost   32.764   \n",
      "Iteration 3000: Cost   32.445   \n",
      "Iteration 4000: Cost   32.346   \n",
      "Iteration 5000: Cost   32.313   \n",
      "Iteration 6000: Cost   32.300   \n",
      "Iteration 7000: Cost   32.294   \n",
      "Iteration 8000: Cost   32.290   \n",
      "Iteration 9000: Cost   32.287   \n"
     ]
    }
   ],
   "source": [
    "ada_grad_norm = AdaGradBiasSep(iteration=10000, lr=1.5)\n",
    "ada_grad_norm.fit(train_x_norm, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93a03f8a-dfc1-4ac5-aee5-787fc4cd2789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffence between Close Form Solution and My Adagrad Norm = 0.266\n"
     ]
    }
   ],
   "source": [
    "ada_nrom_pred = ada_grad_norm.predict(test_x_norm)\n",
    "\n",
    "diff = mean_squared_error(cfs_pred, ada_nrom_pred)\n",
    "print(f\"Diffence between Close Form Solution and My Adagrad Norm = {round(diff, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc81f55-19b9-46a8-b09b-54e684077c48",
   "metadata": {},
   "source": [
    "# What happen if start from best w and b?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d408fed2-9a2a-46bc-be55-8677d88004b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost   32.257   \n",
      "Iteration 1000: Cost   32.257   \n",
      "Iteration 2000: Cost   32.257   \n",
      "Iteration 3000: Cost   32.257   \n",
      "Iteration 4000: Cost   32.257   \n",
      "Iteration 5000: Cost   32.257   \n",
      "Iteration 6000: Cost   32.257   \n",
      "Iteration 7000: Cost   32.257   \n",
      "Iteration 8000: Cost   32.257   \n",
      "Iteration 9000: Cost   32.257   \n"
     ]
    }
   ],
   "source": [
    "best_w = cfs.w\n",
    "gd_sp = GradientDescentBiasSep(iteration=10000, lr=1e-6)\n",
    "gd_sp.fit(train_x, train_y, init_w=best_w[1:], init_b=best_w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4afb8ed-86d4-4553-8ad6-b855a05a5af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffence between Close Form Solution and My Gradient Descent SP = 0.0\n"
     ]
    }
   ],
   "source": [
    "gd_sp_pred = gd_sp.predict(test_x)\n",
    "\n",
    "diff = mean_squared_error(cfs_pred, gd_sp_pred)\n",
    "print(f\"Diffence between Close Form Solution and My Gradient Descent SP = {round(diff, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba3fca-4e89-4683-8d4d-95029508dead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LYH-ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
